{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Import Success!\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import hmmlearn, pomegranate, time, seaborn\n",
    "from hmmlearn.hmm import *\n",
    "from pomegranate import *\n",
    "from seqlearn import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "seaborn.set_style('whitegrid')\n",
    "# import and build\n",
    "print(\"Import Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Error cannot import GHMM\n",
    "#     Using Linux System\n",
    "\n",
    "# 2. Error from seqlearn.hmm import *\n",
    "#    cannot import name 'logsumexp' from 'scipy.misc' (old document)\n",
    "#    https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.misc.logsumexp.html\n",
    "\n",
    "# 3. Error cannot imply mlpy\n",
    "#    conda import fail\n",
    "#    support Linux 64 only\n",
    "#    https://anaconda.org/bioconda/mlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit -> hmmlearn\n",
    "# pomegranate -> yahmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmmlearn version:  0.2.4\n",
      "pomegranate version:  0.14.2\n"
     ]
    }
   ],
   "source": [
    "# library version \n",
    "# GHMM is not supported in Windows. Will try Linux Ubuntu later\n",
    "print (\"hmmlearn version: \", hmmlearn.__version__)\n",
    "print (\"pomegranate version: \", pomegranate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25      , 0.25      , 0.25      , 0.25      ],\n",
       "       [0.        , 0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.        , 0.        , 0.5       , 0.5       ],\n",
       "       [0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate Initial transition matrix\n",
    "def transition_matrix(n_states, topology, randomize=False):\n",
    "    \"\"\"HMM initial transition matrix\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_states: int\n",
    "        The number of states of the HMM. For each state, a mean vector and a covariance matrix are estimated.\n",
    "    topology: string\n",
    "        The transition matrix type.\n",
    "        - full \n",
    "        - left-to-right-1\n",
    "        - left-to-right-2\n",
    "        - left-to-right-full   upper triangular matrix\n",
    "    Returns\n",
    "    -------\n",
    "    transmat: Array\n",
    "        Initialized transition martix\n",
    "    \"\"\"\n",
    "    transmat = np.zeros((n_states, n_states))\n",
    "    if topology.startswith('left-to-right'):\n",
    "        if topology.endswith('-full'):\n",
    "            # In the full 'left-to-right' topology each state has a connection to every other state that is located on\n",
    "            # its right and to itself. The transition matrix is therefore an upper triangular matrix.\n",
    "            for i in range(n_states):\n",
    "                transmat[i, i:] = 1.0 / float(n_states - i)\n",
    "        elif topology.endswith('-1'):\n",
    "            # Delta = 1, hence self transition + transition to next state is allowed.\n",
    "            for i in range(n_states):\n",
    "                if i == n_states-1:\n",
    "                    transmat[i, i] = 1.0\n",
    "                else:\n",
    "                    transmat[i, i] = 0.5\n",
    "                    transmat[i, i+1] = 0.5\n",
    "        elif topology.endswith('-2'):\n",
    "            # Delta = 2, hence self transition + transition to next state + transition to state after next state is allowed.\n",
    "            for i in range(n_states):\n",
    "                if i == n_states-1:\n",
    "                    transmat[i, i] = 1.0\n",
    "                elif i == n_states-2:\n",
    "                    transmat[i, i] = 0.5\n",
    "                    transmat[i, i+1] = 0.5\n",
    "                else:\n",
    "                    transmat[i, i] = 1. / 3.\n",
    "                    transmat[i, i+1] = 1. / 3.\n",
    "                    transmat[i, i+2] = 1. / 3.\n",
    "    elif topology == 'full':\n",
    "        # In the 'full' topology each state is connect with every other state and itself.\n",
    "        transmat[:, :] = 1.0 / float(n_states)\n",
    "    else:\n",
    "        raise ValueError('unknown topology %s' % topology)\n",
    "\n",
    "    if randomize:\n",
    "        transmat *= np.random.random(transmat.shape)\n",
    "        sums = np.sum(transmat, axis=1)\n",
    "        for row_idx in range(transmat.shape[0]):\n",
    "            transmat[row_idx] /= sums[row_idx]\n",
    "    assert np.allclose(np.sum(transmat, axis=1), np.ones(n_states))\n",
    "    return transmat\n",
    "transition_matrix(4, \"full\", True)\n",
    "transition_matrix(4, \"left-to-right-1\")\n",
    "transition_matrix(4, \"left-to-right-2\")\n",
    "transition_matrix(4, \"left-to-right-full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27547266 0.38639081 0.12699169 0.21114484]\n",
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Generate initial start_prob matrix\n",
    "def start_probabilities(n_states, topology, randomize=False):\n",
    "    \"\"\"HMM initial start probabilities matrix\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_states: int\n",
    "        The number of states of the HMM. For each state, a mean vector and a covariance matrix are estimated.\n",
    "    topology: string\n",
    "        The start probabilities matrix type.\n",
    "        - full \n",
    "        - left-to-right\n",
    "    randomize: decide assign random value to state or just 1\n",
    "    Returns\n",
    "    -------\n",
    "    transmat: Array\n",
    "        Initialized start prob martix\n",
    "    \"\"\"\n",
    "    pi = np.zeros(n_states)\n",
    "    if topology.startswith('left-to-right'):\n",
    "        pi[0] = 1.0\n",
    "    elif topology == 'full':\n",
    "        pi[:] = 1.0 / float(n_states)\n",
    "    else:\n",
    "        raise ValueError('unknown topology %s' % topology)\n",
    "\n",
    "    if randomize:\n",
    "        pi *= np.random.random(pi.shape)\n",
    "        pi /= np.sum(pi)\n",
    "\n",
    "    assert np.isclose(np.sum(pi), 1.0)\n",
    "    return pi\n",
    "\n",
    "print(start_probabilities(4, \"full\", True))\n",
    "print(start_probabilities(4, \"left-to-right\", True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate initial mean and covariance parameters\n",
    "def estimate_normal_distribution_params(n_states, n_features):\n",
    "    \"\"\"Estimates parameters (mean and covariance) for a number of states\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_states: int\n",
    "        The number of states of the HMM. For each state, a mean vector and a covariance matrix are estimated.\n",
    "    n_features: int\n",
    "        The number of features of the dataset\n",
    "    Returns\n",
    "    -------\n",
    "    means : array-like, shape=(n_states, n_features)\n",
    "        The means for all states. Each row represents the means for all n_features.\n",
    "    covars: array-like, shape=(n_states, n_features, n_features)\n",
    "        The covars for all states.\n",
    "    \"\"\"\n",
    "    means = np.array([np.random.random(n_features) for _ in range(n_states)])\n",
    "    covars = []\n",
    "    for state in range(n_states):\n",
    "        # Create random semi-definite matrix\n",
    "        covar = np.random.random((n_features, n_features))\n",
    "        covars.append(np.dot(covar, covar.T))\n",
    "    covars = np.array(covars)\n",
    "\n",
    "    return means, covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate two column timeseries data\n",
    "# raw data and diff\n",
    "def generate_timeseries_data(input_csv_file_path):\n",
    "    datasets=[\"Earthquakes/Chinatown_TEST_NEW_1.csv\", \"Earthquakes/Chinatown_TEST_NEW_2.csv\"]\n",
    "    pd_input = pd.read_csv(input_csv_file_path)\n",
    "    pd_array = pd_input.values\n",
    "    end_v = pd_array[:, 23]\n",
    "    pd_array_one = pd_array.flatten()\n",
    "    hours = pd.date_range('2017-01-01', periods = pd_array_one.shape[0], freq = 'H')\n",
    "    timeseries = pd.Series(pd_array_one, index = hours)\n",
    "    # timeSeriesData Format\n",
    "    diff = np.diff(timeseries)\n",
    "    X = np.column_stack([timeseries[1:], diff])\n",
    "    print(\"X\", X)\n",
    "#     plt.figure()\n",
    "#     timeseries.plot()\n",
    "#     plt.title(\"Time Series Data\")\n",
    "#     plt.show()\n",
    "#     timeseries.rolling(window = 12, center = False).mean().plot(style = '-g')\n",
    "#     plt.title(\"Rolling Mean\")\n",
    "#     plt.show()\n",
    "#     timeseries.mean()\n",
    "#     timeseries.max()\n",
    "#     timeseries.min()\n",
    "#     timeseries.describe()\n",
    "    # training data\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameter(obs, n_state, topology, randomize = False):\n",
    "    transmat_ = transition_matrix(n_state, topology, randomize)\n",
    "    startprob_ = start_probabilities(n_state, topology, randomize)\n",
    "    means, covars = estimate_normal_distribution_params(n_state, 2)\n",
    "    return startprob_, transmat_, means, covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmmlearn_model(start_probs, transmat, means, covars, iteration_time):\n",
    "    \"\"\"Return a hmmlearn model.\"\"\"\n",
    "    model = GaussianHMM(n_components=transmat.shape[0], covariance_type='full', n_iter=20)\n",
    "    model.startprob_ = start_probs\n",
    "    model.transmat_ = transmat\n",
    "    model.means_ = means\n",
    "    model._covars_ = covars\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pomegranate_model(start_probs, transmat, n_state, means, covars):\n",
    "    \"\"\"Return a pomegranate model.\"\"\"\n",
    "    # (1) by defining both the distributions and the graphical structure manually\n",
    "    # If you are initializing the parameters manually, you can do so either by passing in a list of distributions \n",
    "    # and a transition matrix, or by building the model line-by-line.\n",
    "    \n",
    "    # (2) running the from_samples method to learn both the structure and distributions directly from data.\n",
    "    distributions = [pomegranate.MultivariateGaussianDistribution(means[i], covars[i]) for i in range(n_state)]\n",
    "\n",
    "    # Create model and states\n",
    "    print(distributions)\n",
    "    states = [pomegranate.base.State(distribution) for distribution in distributions]\n",
    "    model = pomegranate.hmm.HiddenMarkovModel()\n",
    "    model.add_states(states)\n",
    "    \n",
    "    # Start probabilities\n",
    "    for i, prob in enumerate(start_probs):\n",
    "        model.add_transition(model.start, start_probs[i], prob)\n",
    "\n",
    "    # Add transitions\n",
    "    for i, row in enumerate(transmat):\n",
    "        for j, prob in enumerate(row):\n",
    "            if prob != 0.0:\n",
    "                model.add_transition(states[i], states[j], prob)\n",
    "             \n",
    "    # The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
    "    # model = pomegranate.hmm.HiddenMarkovModel.from_matrix(transmat, states, start_probs, merge = 'None')\n",
    "    model.bake()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(seqs, n_state, topology, randomize, iter_time):\n",
    "    hllp, plp = [], []\n",
    "    hlv, pv = [], []\n",
    "    hlm, pm = [], []\n",
    "    hls, ps = [], []\n",
    "    hlt, pt = [], []\n",
    "    likelihood_vect = np.empty([0,1])\n",
    "\n",
    "    # generate initial matrix for two models\n",
    "    start_probs, transmat, means, covars = initialize_parameter(seqs, n_state, topology, randomize)\n",
    "    print(\"start_probs\", start_probs)\n",
    "    print(\"transmat\", transmat)\n",
    "    print(\"means\", means)\n",
    "    print(\"covars\", covars)\n",
    "    learn_model = hmmlearn_model(transmat, start_probs, means, covars, iteration_time = 100)\n",
    "\n",
    "    tic = time.time()\n",
    "    learn_model.fit(seqs)\n",
    "    hlt.append( time.time() - tic )\n",
    "\n",
    "    tic = time.time()\n",
    "    learn_model.score(seqs)\n",
    "    hllp.append( time.time() - tic )\n",
    "\n",
    "    tic = time.time()\n",
    "    learn_model.predict(seqs)\n",
    "    hlv.append( time.time() - tic )  \n",
    "\n",
    "\n",
    "    # get stmc after new interation\n",
    "    new_transmat = learn_model.transmat_\n",
    "    new_start_probs = learn_model.startprob_\n",
    "    new_means = learn_model.means_\n",
    "    new_covars = learn_model.covars_\n",
    "    print(new_transmat)\n",
    "    print(new_start_probs)\n",
    "    print(new_means)\n",
    "    print(new_covars)\n",
    "\n",
    "    # restore model score in likelihood\n",
    "    likelihood_vect = np.vstack((likelihood_vect, learn_model.score(seqs)))\n",
    "    print(\"+++++++likelihood\", likelihood_vect)\n",
    "\n",
    "    # compare to pomegranate model\n",
    "    pome_model = pomegranate_model(start_probs, transmat,  n_state, means, covars)\n",
    "    # bake model before fit\n",
    "\n",
    "    tic = time.time()\n",
    "    pome_model.fit(seqs, max_iterations=100, verbose=False)\n",
    "    pt.append( time.time() - tic )\n",
    "\n",
    "    tic = time.time()\n",
    "    pome_model.log_probability(seqs)\n",
    "    plp.append( time.time() - tic )\n",
    "\n",
    "    tic = time.time()\n",
    "    pome_model.predict(seqs)\n",
    "    pv.append( time.time() - tic )\n",
    "        \n",
    "        \n",
    "    print(\"hllp, \", hllp, \"plp\",  plp)\n",
    "    print(numpy.array(hllp) / numpy.array(plp))\n",
    "    plt.figure( figsize=(12, 8))\n",
    "    plt.xlabel(\"# Components\", fontsize=12 )\n",
    "    plt.ylabel(\"pomegranate / hmmlearn\", fontsize=12 )\n",
    "    plt.plot( numpy.array(hllp) / numpy.array(plp), label=\"Log Probability\")\n",
    "    plt.plot( numpy.array(hlv) / numpy.array(pv), label=\"Viterbi\")\n",
    "    plt.plot( numpy.array(hlm) / numpy.array(pm), label=\"Maximum A Posteriori\")\n",
    "    plt.plot( numpy.array(hlt) / numpy.array(pt), label=\"Training\")\n",
    "    plt.xticks( range(11), range(10, 112, 10), fontsize=12 )\n",
    "    plt.yticks( fontsize=12 )\n",
    "    plt.legend( fontsize=12 )\n",
    "    \n",
    "    return learn_model, pome_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_comparison(n_dims, n_seqs):\n",
    "    hllp, plp = [], []\n",
    "    hlv, pv = [], []\n",
    "    hlm, pm = [], []\n",
    "    hls, ps = [], []\n",
    "    hlt, pt = [], []\n",
    "\n",
    "    for i in range(10, 112, 10):\n",
    "        transmat, start_probs, means, covars, seqs = initialize_components(i, n_dims, n_seqs)\n",
    "        model = hmmlearn_model(transmat, start_probs, means, covars)\n",
    "        print(seqs)\n",
    "        tic = time.time()\n",
    "        for seq in seqs:\n",
    "            model.score(seq)\n",
    "        hllp.append( time.time() - tic )\n",
    "\n",
    "        tic = time.time()\n",
    "        for seq in seqs:\n",
    "            model.predict(seq)\n",
    "        hlv.append( time.time() - tic )\n",
    "\n",
    "        tic = time.time()\n",
    "        for seq in seqs:\n",
    "            model.predict_proba(seq)\n",
    "        hlm.append( time.time() - tic )    \n",
    "        \n",
    "        tic = time.time()\n",
    "        model.fit(seqs.reshape(n_seqs*i, n_dims), lengths=[i]*n_seqs)\n",
    "        hlt.append( time.time() - tic )\n",
    "\n",
    "        model = pomegranate_model(transmat, start_probs, means, covars)\n",
    "\n",
    "        tic = time.time()\n",
    "        for seq in seqs:\n",
    "            model.log_probability(seq)\n",
    "        plp.append( time.time() - tic )\n",
    "\n",
    "        tic = time.time()\n",
    "        for seq in seqs:\n",
    "            model.predict(seq)\n",
    "        pv.append( time.time() - tic )\n",
    "\n",
    "        tic = time.time()\n",
    "        for seq in seqs:\n",
    "            model.predict_proba(seq)\n",
    "        pm.append( time.time() - tic )    \n",
    "        \n",
    "        tic = time.time()\n",
    "        model.fit(seqs, max_iterations=1, verbose=False)\n",
    "        pt.append( time.time() - tic )\n",
    "\n",
    "    plt.figure( figsize=(12, 8))\n",
    "    plt.xlabel(\"# Components\", fontsize=12 )\n",
    "    plt.ylabel(\"pomegranate is x times faster\", fontsize=12 )\n",
    "    plt.plot( numpy.array(hllp) / numpy.array(plp), label=\"Log Probability\")\n",
    "    plt.plot( numpy.array(hlv) / numpy.array(pv), label=\"Viterbi\")\n",
    "    plt.plot( numpy.array(hlm) / numpy.array(pm), label=\"Maximum A Posteriori\")\n",
    "    plt.plot( numpy.array(hlt) / numpy.array(pt), label=\"Training\")\n",
    "    plt.xticks( xrange(11), xrange(10, 112, 10), fontsize=12 )\n",
    "    plt.yticks( fontsize=12 )\n",
    "    plt.legend( fontsize=12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
      "Even though the 'means_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'm'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[  71  -67]\n",
      " [  68   -3]\n",
      " [  60   -8]\n",
      " ...\n",
      " [ 961 -228]\n",
      " [ 690 -271]\n",
      " [ 328 -362]]\n",
      "hidden state 5\n",
      "topology full\n",
      "randomize True\n",
      "start_probs [0.22290901 0.21290444 0.26239807 0.24121962 0.06056885]\n",
      "transmat [[0.21091891 0.23806265 0.01935634 0.26926836 0.26239374]\n",
      " [0.01382375 0.09254112 0.1076803  0.43381383 0.35214101]\n",
      " [0.30572892 0.00207798 0.31245791 0.17975606 0.19997913]\n",
      " [0.11233765 0.31338484 0.19754716 0.23973643 0.13699393]\n",
      " [0.03752133 0.4960249  0.29416863 0.11097569 0.06130945]]\n",
      "means [[0.67582624 0.09325715]\n",
      " [0.95942371 0.20932829]\n",
      " [0.29040065 0.4041841 ]\n",
      " [0.51614405 0.1293591 ]\n",
      " [0.699547   0.5790092 ]]\n",
      "covars [[[0.611549   0.51966888]\n",
      "  [0.51966888 0.48557633]]\n",
      "\n",
      " [[1.49188931 0.50481807]\n",
      "  [0.50481807 0.19233534]]\n",
      "\n",
      " [[0.15534831 0.26611354]\n",
      "  [0.26611354 0.45683853]]\n",
      "\n",
      " [[0.54042511 0.3488604 ]\n",
      "  [0.3488604  0.22833089]]\n",
      "\n",
      " [[0.2395239  0.11608165]\n",
      "  [0.11608165 0.45471231]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Even though the 'covars_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'c'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.81879750e-001 7.36306862e-032 3.25606888e-033 2.18120250e-001\n",
      "  2.89967564e-067]\n",
      " [1.36338576e-083 8.34049077e-001 3.64310144e-074 3.83909525e-002\n",
      "  1.27559970e-001]\n",
      " [1.74121798e-001 2.84966097e-168 8.25878202e-001 4.48706543e-113\n",
      "  2.72360830e-045]\n",
      " [7.87167026e-091 5.41641709e-001 1.78122282e-228 4.58358291e-001\n",
      "  1.35156129e-034]\n",
      " [1.17241079e-061 8.17299934e-032 2.90967434e-001 7.40599229e-030\n",
      "  7.09032566e-001]]\n",
      "[2.12596266e-110 1.41019999e-204 1.00000000e+000 0.00000000e+000\n",
      " 3.58148312e-026]\n",
      "[[ 318.5925666   124.21312992]\n",
      " [1020.58515918  -64.04163179]\n",
      " [  38.16942548   -8.66230157]\n",
      " [1334.49207679  283.66019043]\n",
      " [ 274.73851044 -203.74497433]]\n",
      "[[[ 35132.14368172  15249.11500047]\n",
      "  [ 15249.11500047   9796.24172596]]\n",
      "\n",
      " [[ 29875.23650623  12812.67153313]\n",
      "  [ 12812.67153313  24856.80251395]]\n",
      "\n",
      " [[   459.13175583     88.14847146]\n",
      "  [    88.14847146    761.28195322]]\n",
      "\n",
      " [[ 42973.88804204 -25880.39176854]\n",
      "  [-25880.39176854  77562.26091888]]\n",
      "\n",
      " [[ 33020.87037407  -7127.67579696]\n",
      "  [ -7127.67579696  19834.51575561]]]\n",
      "+++++++likelihood [[-73766.57032129]]\n",
      "[{\n",
      "    \"class\" : \"Distribution\",\n",
      "    \"name\" : \"MultivariateGaussianDistribution\",\n",
      "    \"parameters\" : [\n",
      "        [\n",
      "            0.6758262402548283,\n",
      "            0.09325715253833888\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                0.6115490002541845,\n",
      "                0.5196688757865247\n",
      "            ],\n",
      "            [\n",
      "                0.5196688757865247,\n",
      "                0.48557633202060874\n",
      "            ]\n",
      "        ]\n",
      "    ],\n",
      "    \"frozen\" : false\n",
      "}, {\n",
      "    \"class\" : \"Distribution\",\n",
      "    \"name\" : \"MultivariateGaussianDistribution\",\n",
      "    \"parameters\" : [\n",
      "        [\n",
      "            0.9594237144898597,\n",
      "            0.2093282868891716\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                1.4918893103827453,\n",
      "                0.5048180656264023\n",
      "            ],\n",
      "            [\n",
      "                0.5048180656264023,\n",
      "                0.1923353377743311\n",
      "            ]\n",
      "        ]\n",
      "    ],\n",
      "    \"frozen\" : false\n",
      "}, {\n",
      "    \"class\" : \"Distribution\",\n",
      "    \"name\" : \"MultivariateGaussianDistribution\",\n",
      "    \"parameters\" : [\n",
      "        [\n",
      "            0.2904006483274595,\n",
      "            0.40418409726283566\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                0.155348313076708,\n",
      "                0.26611354246048613\n",
      "            ],\n",
      "            [\n",
      "                0.26611354246048613,\n",
      "                0.45683852920994744\n",
      "            ]\n",
      "        ]\n",
      "    ],\n",
      "    \"frozen\" : false\n",
      "}, {\n",
      "    \"class\" : \"Distribution\",\n",
      "    \"name\" : \"MultivariateGaussianDistribution\",\n",
      "    \"parameters\" : [\n",
      "        [\n",
      "            0.5161440481062292,\n",
      "            0.12935910188522304\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                0.540425107550995,\n",
      "                0.34886040345008734\n",
      "            ],\n",
      "            [\n",
      "                0.34886040345008734,\n",
      "                0.22833089030011922\n",
      "            ]\n",
      "        ]\n",
      "    ],\n",
      "    \"frozen\" : false\n",
      "}, {\n",
      "    \"class\" : \"Distribution\",\n",
      "    \"name\" : \"MultivariateGaussianDistribution\",\n",
      "    \"parameters\" : [\n",
      "        [\n",
      "            0.6995470028444192,\n",
      "            0.5790091959048627\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                0.23952390108770688,\n",
      "                0.11608164816060237\n",
      "            ],\n",
      "            [\n",
      "                0.11608164816060237,\n",
      "                0.45471230554275555\n",
      "            ]\n",
      "        ]\n",
      "    ],\n",
      "    \"frozen\" : false\n",
      "}]\n",
      "Warning: Sequence is impossible.\n",
      "hllp,  [0.011768579483032227] plp [0.03734898567199707]\n",
      "[0.3150977]\n",
      "X [[  71  -67]\n",
      " [  68   -3]\n",
      " [  60   -8]\n",
      " ...\n",
      " [ 961 -228]\n",
      " [ 690 -271]\n",
      " [ 328 -362]]\n",
      "Warning: Sequence is impossible.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_file = \"Earthquakes/Chinatown_TEST_NEW_2.csv\"\n",
    "# generate sequence\n",
    "seqs = generate_timeseries_data(input_file)\n",
    "# generate basic info from sequence\n",
    "n_state = 5\n",
    "topology = \"full\"\n",
    "randomize = True\n",
    "\n",
    "# Iteration Times\n",
    "ITERATION = 1\n",
    "print(\"hidden state %s\" % n_state)\n",
    "\n",
    "\n",
    "\n",
    "print(\"topology %s\" % topology)\n",
    "print(\"randomize %s\" % randomize)\n",
    "hmmlearn_model, pomegranate_model = evaluate_models(seqs, n_state, topology, randomize, ITERATION)\n",
    "\n",
    "# use test data\n",
    "input_test_file = \"Earthquakes/Chinatown_TEST_NEW_2.csv\"\n",
    "test_seqs = generate_timeseries_data(input_file)\n",
    "hmmlearn_predict_result = hmmlearn_model.predict(test_seqs)\n",
    "pomegranate_predict_result = pomegranate_model.predict(test_seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  71  -67]\n",
      " [  68   -3]\n",
      " [  60   -8]\n",
      " ...\n",
      " [ 961 -228]\n",
      " [ 690 -271]\n",
      " [ 328 -362]]\n",
      "[1 1 1 ... 3 3 4]\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7449329f5b4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpomegranate_predict_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhmmlearn_predict_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hmmlearn_predict_result Data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'plot'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_seqs)\n",
    "print(hmmlearn_predict_result)\n",
    "print(pomegranate_predict_result)\n",
    "plt.figure()\n",
    "hmmlearn_predict_result.plot()\n",
    "plt.title(\"hmmlearn_predict_result Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [NormalDistribution(5, 1), NormalDistribution(1, 7), NormalDistribution(8,2)]\n",
    "print(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = DiscreteDistribution({'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25})\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = NormalDistribution(5, 2)\n",
    "d2 = ExponentialDistribution(5)\n",
    "d3 = LogNormalDistribution(2, 0.4)\n",
    "print(d, d2, d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.00531421  9.06074626 10.72784614 11.10348944 10.55412795 11.37806876\n",
      "  9.09995056 10.01643868 10.4201854  10.53254514 11.21549599  9.31488978\n",
      "  8.95151255  9.7198739   9.63921942 11.80933793  8.29931518 10.52191385\n",
      "  9.59899039 10.31294196 10.50172729 10.10912383  9.9639344  11.07467695\n",
      "  9.06049004 10.51445825 11.48598714 10.18456096 10.91597058 10.13404088\n",
      " 11.50829341 10.88108184  8.35323188  8.89100253 10.4369899  11.0812715\n",
      "  9.28580023  9.72420721  8.44490273 10.61755599 10.2860636  11.65733359\n",
      "  9.80997233 11.26986167 10.32972977 11.80054536 10.37215503  9.26611668\n",
      " 10.37833905 11.16629539  8.77762848  8.75137391 10.01099677 10.4235357\n",
      " 10.46259417  9.72326918  8.74853351 10.89350679  9.50084835  9.42105662\n",
      " 11.45141764  8.58835756 10.35538936 10.12382157  9.40054299  9.19074798\n",
      "  9.46916873  9.90470164  9.76657789 10.14918504 10.83141754 11.11795192\n",
      " 10.76189565 10.69998809  9.73213522 10.16793436 11.12228418 10.31815953\n",
      "  7.80395758 10.72618493  9.86488551  9.5572391   9.76522253 12.7230475\n",
      "  8.76070344  9.26957058 10.79682724  9.36266815 10.86617711  9.76804253\n",
      " 11.82045789 11.19236109 10.34821819  9.61150896 10.32072159  8.1335812\n",
      "  9.9474759   9.08995429 10.49193504 10.34918823] {\n",
      "    \"class\" : \"Distribution\",\n",
      "    \"name\" : \"NormalDistribution\",\n",
      "    \"parameters\" : [\n",
      "        10.102228724935207,\n",
      "        0.9471592823684882\n",
      "    ],\n",
      "    \"frozen\" : false\n",
      "} {\n",
      "    \"class\" : \"Distribution\",\n",
      "    \"name\" : \"ExponentialDistribution\",\n",
      "    \"parameters\" : [\n",
      "        0.09898805779686261\n",
      "    ],\n",
      "    \"frozen\" : false\n",
      "} {\n",
      "    \"class\" : \"Distribution\",\n",
      "    \"name\" : \"LogNormalDistribution\",\n",
      "    \"parameters\" : [\n",
      "        2.3082749864245025,\n",
      "        0.0952186951657825\n",
      "    ],\n",
      "    \"frozen\" : false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = numpy.random.normal(10, 1, size=100)\n",
    "\n",
    "d4 = NormalDistribution.from_samples(x)\n",
    "d5 = ExponentialDistribution.from_samples(x)\n",
    "d6 = LogNormalDistribution.from_samples(x)\n",
    "print(\"d4\", d4)\n",
    "print(\"d5\", d5)\n",
    "print(\"d6\", d6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.90840326 8.34013875 9.31161258]]\n",
      "{\n",
      "    \"class\" : \"Distribution\",\n",
      "    \"name\" : \"MultivariateGaussianDistribution\",\n",
      "    \"parameters\" : [\n",
      "        [\n",
      "            8.908403261749736,\n",
      "            8.340138747244533,\n",
      "            9.311612582883926\n",
      "        ],\n",
      "        [\n",
      "            [\n",
      "                1e-05,\n",
      "                0.0,\n",
      "                0.0\n",
      "            ],\n",
      "            [\n",
      "                0.0,\n",
      "                1e-05,\n",
      "                0.0\n",
      "            ],\n",
      "            [\n",
      "                0.0,\n",
      "                0.0,\n",
      "                1e-05\n",
      "            ]\n",
      "        ]\n",
      "    ],\n",
      "    \"frozen\" : false\n",
      "}\n",
      "[8.90840326 8.34013875 9.31161258] [[1.e-05 0.e+00 0.e+00]\n",
      " [0.e+00 1.e-05 0.e+00]\n",
      " [0.e+00 0.e+00 1.e-05]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = numpy.random.normal(10, 1, size=(1, 3))\n",
    "\n",
    "d7 = MultivariateGaussianDistribution.from_samples(x)\n",
    "d7.mu, d7.cov\n",
    "print(x)\n",
    "print(d7)\n",
    "print(d7.mu, d7.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.23338681, 0.27360667, 0.02534593, 0.46766059],\n",
       "        [0.44932472, 0.30991248, 0.23823207, 0.00253073],\n",
       "        [0.10314645, 0.23411211, 0.11218062, 0.55056082],\n",
       "        [0.08057582, 0.47311348, 0.16740712, 0.27890357]]),\n",
       " array([0.37452125, 0.36991264, 0.13382348, 0.12174263]),\n",
       " array([[-0.05145295, -1.07648614],\n",
       "        [-0.66223072, -1.04216088],\n",
       "        [ 0.54383807, -0.74846562],\n",
       "        [ 0.53894553, -1.14151853]]),\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]]),\n",
       " array([[[-1.57118877, -2.2783733 ],\n",
       "         [-1.32938284, -2.3584233 ],\n",
       "         [ 1.20656394,  0.33031774],\n",
       "         [-0.18431972, -1.9539999 ]],\n",
       " \n",
       "        [[ 0.79015541, -1.78315641],\n",
       "         [-2.38148462, -0.51168698],\n",
       "         [ 2.13860267, -3.11292722],\n",
       "         [-0.19147714, -1.07993042]],\n",
       " \n",
       "        [[-0.7233047 ,  1.14982583],\n",
       "         [-0.82705923,  0.1698996 ],\n",
       "         [ 0.09132002, -0.53827712],\n",
       "         [-0.42586582, -0.51930842]],\n",
       " \n",
       "        [[-0.24796424, -1.53410805],\n",
       "         [-0.55544853, -1.71207374],\n",
       "         [ 0.36989082, -1.49530409],\n",
       "         [ 2.39118611, -0.7381344 ]],\n",
       " \n",
       "        [[ 0.3560306 , -0.10823173],\n",
       "         [-0.99512745, -1.59424749],\n",
       "         [-1.85040297, -1.77053538],\n",
       "         [ 1.22681047, -2.21393098]],\n",
       " \n",
       "        [[-2.37051475, -1.37817381],\n",
       "         [-0.92477755, -0.31696309],\n",
       "         [ 1.03405158, -0.96010457],\n",
       "         [-0.97426055, -3.58224984]],\n",
       " \n",
       "        [[ 0.46893395, -1.39883577],\n",
       "         [ 0.34420823,  0.29466256],\n",
       "         [ 1.19651594,  0.16253749],\n",
       "         [ 1.403046  , -0.59468256]],\n",
       " \n",
       "        [[-2.06136577, -0.12257235],\n",
       "         [-0.63126145, -1.2065187 ],\n",
       "         [-0.7298847 , -1.72024838],\n",
       "         [ 1.5210296 ,  0.55224936]],\n",
       " \n",
       "        [[-0.02362816,  0.049481  ],\n",
       "         [-1.43993589, -2.6825108 ],\n",
       "         [ 2.36421819, -0.31897354],\n",
       "         [ 0.05420881, -0.87106648]],\n",
       " \n",
       "        [[-1.7551746 , -1.10509246],\n",
       "         [-0.1980357 , -1.64846088],\n",
       "         [ 1.03407236, -1.63942777],\n",
       "         [ 2.43272481, -2.28505654]]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def initialize_components(n_components, n_dims, n_seqs):\n",
    "    \"\"\"\n",
    "    Initialize a transition matrix for a model with a fixed number of components,\n",
    "    for Gaussian emissions with a certain number of dimensions, and a data set\n",
    "    with a certain number of sequences.\n",
    "    \"\"\"\n",
    "    \n",
    "    transmat = numpy.abs(numpy.random.randn(n_components, n_components))\n",
    "    transmat = (transmat.T / transmat.sum( axis=1 )).T\n",
    "\n",
    "    start_probs = numpy.abs( numpy.random.randn(n_components) )\n",
    "    start_probs /= start_probs.sum()\n",
    "\n",
    "    means = numpy.random.randn(n_components, n_dims)\n",
    "    covars = numpy.ones((n_components, n_dims))\n",
    "    \n",
    "    seqs = numpy.zeros((n_seqs, n_components, n_dims))\n",
    "    for i in range(n_seqs):\n",
    "        seqs[i] = means + numpy.random.randn(n_components, n_dims)\n",
    "        \n",
    "    return transmat, start_probs, means, covars, seqs\n",
    "initialize_components(4, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition\n",
    "array([[0.25      , 0.25      , 0.25      , 0.25      ],\n",
    "       [0.        , 0.33333333, 0.33333333, 0.33333333],\n",
    "       [0.        , 0.        , 0.5       , 0.5       ],\n",
    "       [0.        , 0.        , 0.        , 1.        ]])\n",
    "start\n",
    "[0.14674745 0.29236879 0.43913042 0.12175334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from pomegranate import *\n",
    ">>> d1 = DiscreteDistribution({'A' : 0.35, 'C' : 0.20, 'G' : 0.05, 'T' : 0.40})\n",
    ">>> d2 = DiscreteDistribution({'A' : 0.25, 'C' : 0.25, 'G' : 0.25, 'T' : 0.25})\n",
    ">>> d3 = DiscreteDistribution({'A' : 0.10, 'C' : 0.40, 'G' : 0.40, 'T' : 0.10})\n",
    ">>>\n",
    ">>> s1 = State(d1, name=\"s1\")\n",
    ">>> s2 = State(d2, name=\"s2\")\n",
    ">>> s3 = State(d3, name=\"s3\")\n",
    ">>>\n",
    ">>> model = HiddenMarkovModel('example')\n",
    ">>> model.add_states([s1, s2, s3])\n",
    ">>> model.add_transition(model.start, s1, 0.90)\n",
    ">>> model.add_transition(model.start, s2, 0.10)\n",
    ">>> model.add_transition(s1, s1, 0.80)\n",
    ">>> model.add_transition(s1, s2, 0.20)\n",
    ">>> model.add_transition(s2, s2, 0.90)\n",
    ">>> model.add_transition(s2, s3, 0.10)\n",
    ">>> model.add_transition(s3, s3, 0.70)\n",
    ">>> model.add_transition(s3, model.end, 0.30)\n",
    ">>> model.bake()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
